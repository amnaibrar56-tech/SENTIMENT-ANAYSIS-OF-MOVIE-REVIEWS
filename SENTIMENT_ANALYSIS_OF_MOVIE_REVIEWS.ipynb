{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT FILES"
      ],
      "metadata": {
        "id": "aplagBu_QKOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJzUrZGlQNE2",
        "outputId": "80c87f38-6c0b-4196-8527-6746e6b81384"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING DATASET"
      ],
      "metadata": {
        "id": "4hyuqSoFSYiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/IMDB Dataset.csv.zip\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxRUu_GrSbeC",
        "outputId": "d99e449b-bdce-40ea-8c38-208ff5bbc9df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "cpehzQNTS47C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['clean_review'] = df['review'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "FPF8bXLIS8BD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split dataset\n",
        "X = df['clean_review']\n",
        "y = df['sentiment'].map({'positive': 1, 'negative': 0})  # encode labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Feature Extraction (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "7houIOQiSXws"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINING"
      ],
      "metadata": {
        "id": "d8rbXPr8TX_q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LENEDzhEPtwp",
        "outputId": "0322a0be-9388-42da-a5ed-6f4219731ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Logistic Regression Performance:\n",
            "Accuracy: 0.889\n",
            "F1 Score: 0.8913469068128426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.89      4961\n",
            "           1       0.88      0.90      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            " Naïve Bayes Performance:\n",
            "Accuracy: 0.8546\n",
            "F1 Score: 0.8566074950690336\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85      4961\n",
            "           1       0.85      0.86      0.86      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            " SVM Performance:\n",
            "Accuracy: 0.8826\n",
            "F1 Score: 0.8846984875270084\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      4961\n",
            "           1       0.88      0.89      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 6: Train Models\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred_lr = lr.predict(X_test_vec)\n",
        "\n",
        "# Naïve Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_vec, y_train)\n",
        "y_pred_nb = nb.predict(X_test_vec)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train_vec, y_train)\n",
        "y_pred_svm = svm.predict(X_test_vec)\n",
        "\n",
        "# Step 7: Evaluation\n",
        "print(\"\\n Logistic Regression Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"\\n Naïve Bayes Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "print(\"\\n SVM Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ]
    }
  ]
}